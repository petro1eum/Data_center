// Пресеты для популярных моделей
export const MODEL_PRESETS = {
    "llama3-8b": { name: "LLaMA 3.1 8B", params: 8, tokensPerSec: 90, description: "Эффективная и производительная модель из последнего поколения Llama.", recommended: true, supports_tool_calls: true },
    "llama2-7b": { name: "LLaMA 2 7B", params: 7, tokensPerSec: 100, description: "Компактная версия LLaMA 2, подходит для задач с ограниченными вычислительными ресурсами, обеспечивает хороший баланс между производительностью и требованиями к памяти.", recommended: false, supports_tool_calls: false },
    "llama2-13b": { name: "LLaMA 2 13B", params: 13, tokensPerSec: 60, description: "Средняя модель в семействе LLaMA 2, предлагает улучшенную точность при умеренных требованиях к оборудованию.", recommended: true, supports_tool_calls: false },
    "llama2-70b": { name: "LLaMA 2 70B", params: 70, tokensPerSec: 12, description: "Крупнейшая модель LLaMA 2, обеспечивает высшее качество генерации и распознавания контекста, требует значительных вычислительных ресурсов.", recommended: false, supports_tool_calls: false },
    "llama3-70b": { name: "LLaMA 3 70B", params: 70, tokensPerSec: 15, description: "Модель последнего поколения LLaMA с улучшенной производительностью и возможностями по сравнению с LLaMA 2 при том же количестве параметров.", recommended: true, supports_tool_calls: true },
    "llama3-405b": { name: "LLaMA 3.1 405B", params: 405, tokensPerSec: 3, description: "Сверхкрупная модель LLaMA 3.1, предназначенная для исследовательских задач и случаев, требующих максимальной точности и качества.", recommended: false, supports_tool_calls: true },
    "mixtral-8x7b": { name: "Mixtral 8x7B", params: 47, tokensPerSec: 20, description: "Экспертная смесь из 8 моделей по 7B параметров, обеспечивает превосходное качество при меньших вычислительных затратах, чем монолитные модели сопоставимого размера.", recommended: true, supports_tool_calls: true },
    "qwen-72b": { name: "Qwen 72B", params: 72, tokensPerSec: 10, description: "Модель от Alibaba, демонстрирующая сильные результаты в задачах понимания и генерации текста для множества языков.", recommended: false, supports_tool_calls: true },
    "qwen2-72b": { name: "Qwen2 72B", params: 72, tokensPerSec: 12, description: "Улучшенная версия Qwen с оптимизацией производительности и точности.", recommended: false, supports_tool_calls: true },
    "qwen2.5-72b": { name: "Qwen2.5 72B", params: 72, tokensPerSec: 14, description: "Модель среднего поколения Qwen с улучшенными возможностями рассуждения.", recommended: false, supports_tool_calls: true },
    "qwen3-235b": { name: "Qwen3 235B", params: 235, tokensPerSec: 4, description: "Флагманская модель семейства Qwen, одна из крупнейших открытых моделей с высочайшей точностью и широким охватом задач.", recommended: true, supports_tool_calls: true },
    "deepseek-67b": { name: "DeepSeek LLM 67B", params: 67, tokensPerSec: 14, description: "Модель с открытым исходным кодом, обученная на масштабном корпусе данных, показывает отличные результаты в задачах программирования и решения проблем.", recommended: false, supports_tool_calls: true },
    "deepseek-v3-671b": { name: "DeepSeek V3 671B", params: 671, tokensPerSec: 2, description: "Крупнейшая модель от DeepSeek, предназначенная для исследовательских и высокоточных коммерческих приложений.", recommended: false, supports_tool_calls: true },
    "yi-34b": { name: "Yi 34B", params: 34, tokensPerSec: 20, description: "Модель от 01.AI, сочетающая эффективность и качество, хорошо работает с многоязычным контентом.", recommended: false, supports_tool_calls: true },
    "qwq-32b": { name: "QwQ 32B", params: 32, tokensPerSec: 30, description: "Высокопроизводительная модель, оптимизированная для скорости генерации с сохранением высокого качества вывода.", recommended: false, supports_tool_calls: false },
  };